{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import argparse\n",
    "from itertools import chain\n",
    "from functools import partial\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, Trainer, TrainingArguments\n",
    "from transformers import AutoModelForTokenClassification, DataCollatorForTokenClassification\n",
    "import evaluate\n",
    "from datasets import Dataset, features\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip3 list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the kaggle provided data\n",
    "* Loading jsons\n",
    "* Downsampling negative samples of the data\n",
    "* Defining and applying tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.load(open(\"kaggle/input/pii-detection-removal-from-educational-data/train.json\"))\n",
    "\n",
    "# downsampling of negative examples\n",
    "p=[] # positive samples (contain relevant labels)\n",
    "n=[] # negative samples (presumably contain entities that are possibly wrongly classified as entity)\n",
    "for d in data:\n",
    "    if any(np.array(d[\"labels\"]) != \"O\"): p.append(d)\n",
    "    else: n.append(d)\n",
    "print(\"original datapoints: \", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = sorted(list(set(chain(*[x[\"labels\"] for x in data]))))\n",
    "label2id = {l: i for i,l in enumerate(all_labels)}\n",
    "id2label = {v:k for k,v in label2id.items()}\n",
    "\n",
    "target = [\n",
    "    'B-EMAIL', 'B-ID_NUM', 'B-NAME_STUDENT', 'B-PHONE_NUM', \n",
    "    'B-STREET_ADDRESS', 'B-URL_PERSONAL', 'B-USERNAME', 'I-ID_NUM', \n",
    "    'I-NAME_STUDENT', 'I-PHONE_NUM', 'I-STREET_ADDRESS', 'I-URL_PERSONAL'\n",
    "]\n",
    "\n",
    "print(id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(example, tokenizer, label2id, max_length):\n",
    "\n",
    "    # rebuild text from tokens\n",
    "    text = []\n",
    "    labels = []\n",
    "\n",
    "    for t, l, ws in zip(\n",
    "        example[\"tokens\"], example[\"provided_labels\"], example[\"trailing_whitespace\"]\n",
    "    ):\n",
    "        text.append(t)\n",
    "        labels.extend([l] * len(t))\n",
    "\n",
    "        if ws:\n",
    "            text.append(\" \")\n",
    "            labels.append(\"O\")\n",
    "\n",
    "    # actual tokenization\n",
    "    tokenized = tokenizer(\"\".join(text), return_offsets_mapping=True, max_length=max_length)\n",
    "\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    text = \"\".join(text)\n",
    "    token_labels = []\n",
    "\n",
    "    for start_idx, end_idx in tokenized.offset_mapping:\n",
    "        # CLS token\n",
    "        if start_idx == 0 and end_idx == 0:\n",
    "            token_labels.append(label2id[\"O\"])\n",
    "            continue\n",
    "\n",
    "        # case when token starts with whitespace\n",
    "        if text[start_idx].isspace():\n",
    "            start_idx += 1\n",
    "\n",
    "        token_labels.append(label2id[labels[start_idx]])\n",
    "\n",
    "    length = len(tokenized.input_ids)\n",
    "\n",
    "    return {**tokenized, \"labels\": token_labels, \"length\": length}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing the data utilizing deberta tokenizer\n",
    "TRAIN_MODEL_PATH = \"microsoft/deberta-base\"\n",
    "TRAIN_MAX_LENGTH = 1024\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(TRAIN_MODEL_PATH)\n",
    "\n",
    "ds = Dataset.from_dict({\n",
    "    \"full_text\": [x[\"full_text\"] for x in data],\n",
    "    \"document\": [str(x[\"document\"]) for x in data],\n",
    "    \"tokens\": [x[\"tokens\"] for x in data],\n",
    "    \"trailing_whitespace\": [x[\"trailing_whitespace\"] for x in data],\n",
    "    \"provided_labels\": [x[\"labels\"] for x in data],\n",
    "})\n",
    "\n",
    "ds = ds.map(tokenize, fn_kwargs={\"tokenizer\": tokenizer, \"label2id\": label2id, \"max_length\": TRAIN_MAX_LENGTH}, num_proc=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(df, percent):\n",
    "    df = df.copy()\n",
    "\n",
    "    df['is_labels'] = df['provided_labels'].apply(lambda labels: any(label != \"O\" for label in labels))\n",
    "    true_samples = df[df['is_labels'] == True]\n",
    "    false_samples = df[df['is_labels'] == False]\n",
    "\n",
    "    downsampled_false_samples = false_samples.sample(frac=percent, random_state=42)\n",
    "\n",
    "\n",
    "    return pd.concat([true_samples, downsampled_false_samples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample the negative samples of the dataset\n",
    "df_train = pd.DataFrame(ds)\n",
    "df_train = downsample(df_train, 0.2)\n",
    "df_train = df_train.drop(columns=['is_labels'])\n",
    "\n",
    "ds = Dataset.from_pandas(df_train)\n",
    "# Splitting the dataset into training and validation sets for performance evaluation\n",
    "ds = ds.train_test_split(test_size=0.1, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ds['train'][0]\n",
    "\n",
    "for t,l in zip(x[\"tokens\"], x[\"provided_labels\"]):\n",
    "    if l != \"O\":\n",
    "        print((t,l))\n",
    "\n",
    "print(\"*\"*100)\n",
    "\n",
    "for t, l in zip(tokenizer.convert_ids_to_tokens(x[\"input_ids\"]), x[\"labels\"]):\n",
    "    if id2label[l] != \"O\":\n",
    "        print((t,id2label[l]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and evaluation of model\n",
    "* Defining metrics (precision, recall, and f5-score)\n",
    "* Training model\n",
    "* Evaluating on validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.metrics import precision_score, recall_score\n",
    "\n",
    "def metrics(p, all_labels):\n",
    "    preds, labels = p\n",
    "    preds = np.argmax(preds, axis=2)\n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "            [all_labels[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "            for prediction, label in zip(preds, labels)\n",
    "        ]\n",
    "    true_labels = [\n",
    "            [all_labels[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "            for prediction, label in zip(preds, labels)\n",
    "        ]\n",
    "\n",
    "    precision = precision_score(true_labels, true_predictions, average='micro')\n",
    "    recall = recall_score(true_labels, true_predictions, average='micro')\n",
    "\n",
    "    f5_score = (1 + 5 ** 2) * (precision * recall) / (5 ** 2 * precision + recall)\n",
    "\n",
    "    results = {\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f5\": f5_score\n",
    "    }\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    TRAIN_MODEL_PATH,\n",
    "    num_labels=len(all_labels),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    ignore_mismatched_sizes=True\n",
    ")\n",
    "# mps GPU acceleration for training \n",
    "if torch.backends.mps.is_available():\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    model.to(mps_device)\n",
    "    print(\"Model moved to MPS device.\")\n",
    "elif torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "    print(\"Model moved to CUDA device.\")\n",
    "else:\n",
    "    print(\"No GPU available, using CPU.\")\n",
    "\n",
    "collator = DataCollatorForTokenClassification(tokenizer, pad_to_multiple_of=16)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir='kaggle/output', \n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=2,\n",
    "    report_to=\"none\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    do_eval=False,\n",
    "    save_total_limit=1,\n",
    "    logging_steps=20,\n",
    "    lr_scheduler_type='cosine',\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True,\n",
    "    warmup_ratio=0.1,\n",
    "    weight_decay=0.01\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=ds['train'],\n",
    "    eval_dataset=ds[\"test\"],\n",
    "    data_collator=collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=partial(metrics, all_labels=all_labels)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()\n",
    "trainer.save_model(\"deberta3base_1024_downsampled\")\n",
    "tokenizer.save_pretrained(\"deberta3base_1024_downsampled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"content/deberta3base_1024_downsampled\"\n",
    "\n",
    "# Load the tokenizer and the model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_path)\n",
    "model.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "        \".\",\n",
    "        per_device_eval_batch_size=1,\n",
    "        report_to=\"none\",\n",
    "    )\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    data_collator=collator,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_regex = re.compile(r'[\\w.+-]+@[\\w-]+\\.[\\w.-]+')\n",
    "phone_num_regex = re.compile(r\"(\\(\\d{3}\\)\\d{3}\\-\\d{4}\\w*|\\d{3}\\.\\d{3}\\.\\d{4})\\s\")\n",
    "regex_dict = {email_regex: label2id[\"B-EMAIL\"], phone_num_regex: label2id[\"B-PHONE_NUM\"]}\n",
    "\n",
    "# Use the regex patterns to be able to label tokens in dataset as email or phone number, think about utilizing offset mapping given by the dataset for proper labeling\n",
    "# I have a list of tokens and I want to label them as email or phone number\n",
    "def label_email_num(regex_dict, tokens, preds):\n",
    "    for i in range(len(tokens)):\n",
    "        for j in range(len(tokens[i])):\n",
    "            token = tokens[i][j]\n",
    "        for regex, id in regex_dict.items():\n",
    "            if regex.match(token):\n",
    "                preds[i] = id\n",
    "    return preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_batch = ds['test'][0:15]\n",
    "preds,labels,metric = trainer.predict(ds['test'])\n",
    "# preds,labels,metric = trainer.predict(test_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [x['tokens'] for x in ds['test']]\n",
    "preds2 = label_email_num(regex_dict, tokens, preds)\n",
    "differences = sum(a != b for a, b in zip(preds, preds2))\n",
    "metrics((preds, labels), all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(example, tokenizer, max_length):\n",
    "\n",
    "    # rebuild text from tokens\n",
    "    text = []\n",
    "    for t, ws in zip(example[\"tokens\"], example[\"trailing_whitespace\"]):\n",
    "        text.append(t)\n",
    "        if ws:\n",
    "            text.append(\" \")\n",
    "\n",
    "    # actual tokenization\n",
    "    tokenized = tokenizer(\"\".join(text), return_offsets_mapping=True, max_length=max_length)\n",
    "\n",
    "    length = len(tokenized.input_ids)\n",
    "\n",
    "    return {**tokenized, \"length\": length}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = json.load(open(\"kaggle/input/pii-detection-removal-from-educational-data/test.json\"))\n",
    "test_frame = pd.DataFrame(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "        \".\",\n",
    "        per_device_eval_batch_size=1,\n",
    "        report_to=\"none\",\n",
    "    )\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    data_collator=collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=partial(metrics, all_labels=all_labels)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset from test_data, tokenize it and predict\n",
    "# test data provides no labels just dict_keys(['document', 'full_text', 'tokens', 'trailing_whitespace'])\n",
    "# test data is a list of dictionaries\n",
    "\n",
    "ds_test = Dataset.from_pandas(test_frame)\n",
    "ds_test = ds_test.map(tokenize, fn_kwargs={\"tokenizer\": tokenizer, \"max_length\": TRAIN_MAX_LENGTH}, num_proc=3)\n",
    "\n",
    "preds,_,_ = trainer.predict(ds_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_output(test_frame, id2label, preds):\n",
    "    preds = np.argmax(preds, axis=2)\n",
    "    output = []\n",
    "    for i, row in test_frame.iterrows():\n",
    "        tokens = row[\"tokens\"]\n",
    "        prediction = preds[i]\n",
    "        for j, token in enumerate(tokens):\n",
    "            if j < len(prediction):  # Check if index is within the range of prediction size\n",
    "                label = id2label[prediction[j]]\n",
    "                if label != \"O\":\n",
    "                    output.append((i, row['document'], j, label))  # Include the missing column \"token\"\n",
    "            else:\n",
    "                break\n",
    "\n",
    "    # Create a dataframe from the output list\n",
    "    df_output = pd.DataFrame(output, columns=[\"row_id\", \"document\", \"token\", \"label\"])  # Update column names\n",
    "\n",
    "    # Save the dataframe to a CSV file\n",
    "    df_output.to_csv(\"kaggle/output/output.csv\", index=False)\n",
    "\n",
    "    return df_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_output(test_frame, id2label, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
